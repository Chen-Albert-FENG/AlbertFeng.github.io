<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="viewport" content="width=800">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    .hp-photo{ width:240px; height:240px; border-radius:240px; -webkit-border-radius:240px; -moz-border-radius:240px; }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 24px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
    </style>

    <title>Chen (Albert) Feng</title>
    <!--<link rel="stylesheet" type="text/css" href="/imgs/css" >-->
    <link rel="icon" type="image/png" href="./imgs/photo.jpg">
</head>

<body>
<table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
<tbody>
<tr>
<td>


    <!--SECTION 1 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="68%" valign="middle">
                <p align="center"><name>Chen (Albert) Feng</name></p>
                    I am a Ph.D. student in <a href="https://ece.hkust.edu.hk/">Dept of Electronic and Computer Engineering (ECE)</a>
                    at <a href="https://hkust.edu.hk/">The Hong Kong University of Science and Technology</a>,
                    supervised by <a href="https://uav.hkust.edu.hk/group/"> Prof. Shaojie Shen</a>.
                    Prior to HKUST, I obtained a B.Eng from <a href="http://en.hit.edu.cn/"> Harbin Institute of Technology </a> and majored in Mechatronics Engineering (ME) in 2021 in the 
                    <a href="http://robot.hit.edu.cn/"> State Key Laboratory of Robotics and System</a>.

                    </br></br>
                    I was a research intern from May. 2021 to Sept. 2021 at <a href="https://www.megvii.com/megvii_research">Megvii Research</a> of <a href="https://www.megvii.com">Megvii</a> (Beijing, China).
                    In my undergraduate study, I was an team member of computer vision group and mechanics group in <a href="https://hitcrt.com/">
                    Harbin Institute of Technology Competition Robotics Team (HITCRT)</a>, named I Hiter (Harbin, China).

                    </br></br>

	            </br>
                </p><p align="center">
                    <a href="mailto:cfengag[-at-]connect.ust.hk">Email</a> /
                    <a href="https://scholar.google.com/citations?user=s71byDsAAAAJ&hl=en">Google Scholar</a> /
                    <a href="https://github.com/AlbertFeng-0405"> Github </a>
                </p>
              </td>
			  <td align="right"> <img class="hp-photo" src="./imgs/photo.jpg" style="width: 170; height: 225;"></td></tr>
            </tbody>
          </table>
    <!--SECTION 2 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td>
          <heading>Education</heading>
		   </td></tr>
       </tbody>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody><tr>
         <td width="20%"><img src="./imgs/hkust.png" alt="PontTuset" width="100" height="140" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p>
                    <b>Ph.D. Student</b> | Electronic and Computer Engineering (ECE), HKUST<br>
                    Time: 2021 - Present. Supervisor: <a href="https://uav.hkust.edu.hk/group/">Prof. Shaojie Shen</a>
                </p>

                </p><p></p>
            </td>
        </tr>

        <td width="20%"><img src="./imgs/hit.jpeg" alt="PontTuset" width="160" height="140" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p>
                    <b>B.Eng</b> | Mechatronics Engineering (ME), HIT<br>
                    Time: 2017 - 2021.
                </p>

                </p><p></p>
            </td>
        </tr>

    </tbody>
    </table> 

    <!--SECTION 3 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td>
          <heading>Research</heading>
           <p align="justify">Now I'm Ph.D. student of <a href="https://uav.hkust.edu.hk/current-members/">HKUST Aerial Robotics Group</a> supervised by <a href="https://uav.hkust.edu.hk/group/"> Prof. Shaojie Shen</a>.  
		   I'm interested in robotics and deep learning. 
           Before HKUST, My research worked on lane detection and trajectory prediction in autonomous driving. 
           In the present stage, I focus on autonomous aerial reconstruction, coverage path planning, and 3D scene understanding collborating with <a href="https://boyuzhou.net/">Boyu Zhou</a>.
		   </p>
		   </td></tr>
       </tbody>
    </table>
    
    <!--SECTION 4 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
          <td><heading>Publications</heading>
          </td>
	</tr></tbody>
    </table>
    
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		<tbody><tr>
			<br> (<sup>#</sup> for the corresponding author, <sup>*</sup> for equal contributions)
        
        <td width="20%"><img src="./imgs/system_overview.png" alt="PontTuset" width="250" height="130" style="border-style: none"></td>
        <td width="80%" valign="top">
                <p><a href="https://2024.ieee-icra.org/">
                <papertitle>FC-Planner: A Skeleton-guided Planning Framework for Fast Aerial Coverage of Complex 3D Scenes</papertitle></a>
                <br> <strong>Chen Feng</strong>, Haojia Li, Jinqi Jiang, Xinyi Chen, Shaojie Shen, and Boyu Zhou<sup>#</sup>.
                <br> <strong>[Under Review]</strong> Submitted to IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>)</em>,
                2024. Yokohama, Japan.
                <br>
                <!-- <a href="https://ieeexplore.ieee.org/document/10238733">paper</a> / -->
                <a href="https://www.bilibili.com/video/BV1Cw41127nn/?spm_id_from=333.999.0.0&vd_source=0af61c122e5e37c944053b57e313025a">video</a>

                </p><p></p>
                <p align="justify" style="font-size:13px"> We propose <strong>FC-Planner</strong>, a skeleton-guided planning framework tailored for fast coverage 
                    of large and complex 3D scenes, which results in the generation of high-quality coverage paths and high computational efficiency. </p>
            </td>
        </tr>

        <td width="20%"><img src="./imgs/dataset2024.jpg" alt="PontTuset" width="250" height="200" style="border-style: none"></td>
        <td width="80%" valign="top">
                <p><a href="https://2024.ieee-icra.org/">
                <papertitle>MASSTAR: A Multi-Modal Large-Scale Scene Dataset with a Versatile Toolchain for Surface Prediction and Completion </papertitle></a>
                <br> Jinqi Jiang<sup>*</sup>, Guiyong Zheng<sup>*</sup>, <strong>Chen Feng</strong><sup>*</sup>, Shaojie Shen, and Boyu Zhou<sup>#</sup>.
                <br> <strong>[Under Review]</strong> Submitted to IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>)</em>,
                2024. Yokohama, Japan.
                <br>
                <!-- <a href="https://ieeexplore.ieee.org/document/10238733">paper</a> / -->
                <a href="https://www.bilibili.com/video/BV1iN411J7Gr/?spm_id_from=333.999.0.0&vd_source=0af61c122e5e37c944053b57e313025a">video</a>

                </p><p></p>
                <p align="justify" style="font-size:13px"> We propose <strong>MASSTAR</strong>, a multi-modal large-scale scene dataset composed of
                    over a thousand collected scene-level 3D data, which could be used for training and testing different learning methods.
                    Additionally, a versatile and highly automatic toolchain is developed to generate a multi-modal dataset only from 3D model sets. </p>
            </td>
        </tr>

        <td width="20%"><img src="./imgs/macformer.png" alt="PontTuset" width="250" height="130" style="border-style: none"></td>
        <td width="80%" valign="top">
	            <p><a href="https://www.ieee-ras.org/publications/ra-l">
	            <papertitle>MacFormer: Map-Agent Coupled Transformer for Real-time and Robust Trajectory Prediction</papertitle></a>
                <br> <strong>Chen Feng</strong>, Hangning Zhou, Huadong Lin, Zhigang Zhang, Ziyao Xu, Chi Zhang, Boyu Zhou<sup>#</sup>, and Shaojie Shen.
                <br> IEEE Robotics and Automation Letters (<strong>RA-L</strong>), 2023. Presented at <strong>ICRA</strong> 2024, Yokohama, Japan.</em>
                <br>
                <a href="https://ieeexplore.ieee.org/document/10238733">paper</a> /
                <a href="https://www.youtube.com/watch?v=XY388iI6sPQ">video</a>

                </p><p></p>
			    <p align="justify" style="font-size:13px"> We propose <strong>MacFormer</strong>, an one-stage Map-Agent Coupled Transformer for real-time and robust trajectory prediction
                    that explicitly incorporates map constraints into the network achieving state-of-the-art performance with significantly lower inference latency and fewer parameters. </p>
            </td>
        </tr>

        <td width="20%"><img src="./imgs/autotrans.jpg" alt="PontTuset" width="250" height="130" style="border-style: none"></td>
        <td width="80%" valign="top">
	            <p><a href="https://www.ieee-ras.org/publications/ra-l">
	            <papertitle>AutoTrans: A Complete Planning and Control Framework for Autonomous UAV Paylaod Transportation</papertitle></a>
                <br> Haojia Li, Haokun Wang, <strong>Chen Feng</strong>, Fei Gao<sup>#</sup>, Boyu Zhou<sup>#</sup>, and Shaojie Shen.
                <br> IEEE Robotics and Automation Letters (<strong>RA-L</strong>), 2023. Presented at <strong>ICRA</strong> 2024, Yokohama, Japan.</em>
                <br>
                <a href="https://ieeexplore.ieee.org/document/10243043">paper</a> /
                <a href="https://github.com/HKUST-Aerial-Robotics/AutoTrans">code</a> /
                <a href="https://www.youtube.com/watch?v=X9g-ivBqy5g">video</a>

                </p><p></p>
			    <p align="justify" style="font-size:13px"> We propose <strong>AutoTrans</strong>, a systematic solution for fully autonomous aerial payload transportation
                that includes a real-time planning solution to generate smooth trajectories and an adaptive NMPC with a hierarchical disturbance compensation strategy to overcome unknown external
                perturbations as well as inaccurate model parameters. </p>
            </td>
        </tr>

        <td width="20%"><img src="./imgs/sys_big.png" alt="PontTuset" width="250" height="130" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="https://www.icra2023.org/">
	            <papertitle>PredRecon: A Prediction-boosted Planning Framework for Fast and High-quality Autonomous Aerial Reconstruction</papertitle></a>
                <br> <strong>Chen Feng</strong>, Haojia Li, Fei Gao, Boyu Zhou<sup>#</sup>, and Shaojie Shen.
                <br> IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>)</em>,
                    2023. London, UK.
                <br>
                <a href="https://ieeexplore.ieee.org/document/10160933">paper</a> /
                <a href="https://github.com/HKUST-Aerial-Robotics/PredRecon">code</a> /
                <a href="https://www.youtube.com/watch?v=ek7yY_FZYAc">video</a> /
                <a href="./imgs/ICRA23.pdf">poster</a> 

                </p><p></p>
			    <p align="justify" style="font-size:13px"> We propose <strong>PredRecon</strong>, a prediction-boosted planning framework that can efficiently
reconstruct high-quality 3D models for the target areas in unknown environments with a single flight.</p>
            </td>
        </tr>
        
        <td width="20%"><img src="./imgs/tenet.png" alt="PontTuset" width="250" height="130" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="https://arxiv.org/abs/2207.00170">
	            <papertitle>TENET: Transformer Encoding Network for Effective Temporal Flow on Motion Prediction</papertitle></a>
                <br> Yuting Wang<sup>*</sup>, Hangning Zhou<sup>*,#</sup>, Zhigang Zhang<sup>*</sup>, <strong>Chen Feng</strong>, Huadong Lin, Chaofei Gao, Yizhi Tang, Zhenting Zhao, Shiyu Zhang, Jie Guo, Xuefeng Wang, Ziyao Xu, and Chi Zhang.
                <br> IEEE / CVF Computer Vision and Pattern Recognition Conference Workshop on Autonomous Driving (<strong>CVPRW</strong>)</em>,
                    2022. New Orleans, USA.
                <br>
                <a href="https://arxiv.org/pdf/2207.00170.pdf">paper</a>

                </p><p></p>
			    <p align="justify" style="font-size:13px"> We propose <strong>TENET</strong> to enhance the trajectory temporal encoding via Temporal Flow Header. Besides, an efficient K-means ensemble method is used. Using our Transformer network and ensemble method, we win the <strong> first place of Argoverse 2 Motion Forecasting Challenge </strong> with the
<strong> state-of-the-art </strong> brier-minFDE score of 1.90. </p>
            </td>
        </tr>

    </tbody>
    </table> 

    <!--SECTION 8 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td>
          <heading>Honors</heading>
          <p>Jun. 2021, Outstanding Graduate - Harbin Institute of Technology </p>
          <p>Sep. 2020, ICRA AI Challenge Second place - IEEE </p>
          <p>Aug. 2020, ABU ROBOCON Robotics competition First Prize - ABU </p>
          <p>Mar. 2020, Outstanding members in Communist Youth League - Harbin Institute of Technology</p>
          <p>Nov. 2019, 'Prof. Zhejun Yuan' Science and Technology Innovation Scholarship - Harbin Institute of Technology</p>
	  <p>Aug. 2019, National university students robotics competition, RoboMaster First Prize - DJI</p>
          <p>Dec. 2018, Outstanding student - Harbin Institute of Technology</p>
          <p>Dec. 2018, National Scholarship - Harbin Institute of Technology</p>
          <p>May. 2018, People Scholarship - Harbin Institute of Technology</p>
		   </td></tr>
       </tbody>
    </table>

    <!--SECTION 8 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td>
          <heading>About Me</heading>
              <p> <strong>Skills</strong>: Python / C ++ / Matlab, PyTorch / MegEngine, Linux, ROS, OpenCV, SolidWorks, Adams, ANSYS, Mechanical design</p>
		   </td></tr>
       </tbody>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
            <td width="100%" align="middle">
            <p align="center" style="width: 25% ">
            <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=xkVDQxg8nSSD4gBPK_6qDjaYSleekdvNsK5tLhNM_xk"></script>
            </p></td>
        </tr>
        </tbody>
    </table>

    <!--SECTION 10 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
         <tbody><tr>
            <td><br>
		       <p align="right"><font size="2"> Last update: 2023.04.26. <a href="http://www.cs.berkeley.edu/~barron/">Thanks.</a></font></p>
            </td>
         </tr>
         </tbody>
     </table>


</td>
</tr>
</tbody>
</table>
</body>
</html>
